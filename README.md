<h1 align="center">ğŸ“˜ Research Paper Summarizer</h1>
<h3 align="center"><i>AI-Powered Research Understanding Tool</i></h3>

<p align="center">
An interactive Generative AI application built using <b>LangChain</b>, 
<b>Hugging Face (Zephyr-7B)</b>, and <b>Streamlit</b> to generate 
structured summaries of AI/ML research papers.
</p>

<hr>

<h2>âœ¨ Overview</h2>

<ul>
  <li>ğŸ“š Select from influential AI research papers</li>
  <li>ğŸ¯ Customize explanation style</li>
  <li>ğŸ“ Control summary length</li>
  <li>ğŸ§  Generate structured, context-aware summaries</li>
  <li>ğŸš« Reduce hallucination with controlled prompting</li>
</ul>

<hr>

<h2>ğŸš€ Core Features</h2>

<ul>
  <li><b>Dynamic Prompt Injection</b> using <code>PromptTemplate</code></li>
  <li><b>Runnable Chain Execution</b> (<code>template | model</code>)</li>
  <li>Multiple explanation styles:
    <ul>
      <li>Beginner-Friendly</li>
      <li>Technical</li>
      <li>Code-Oriented</li>
      <li>Mathematical</li>
    </ul>
  </li>
  <li>Adjustable summary length (Short / Medium / Long)</li>
  <li>Hugging Face API-based inference</li>
  <li>Clean and interactive Streamlit UI</li>
</ul>

<hr>

<h2>ğŸ—ï¸ Architecture</h2>

<pre>
User Input (Streamlit UI)
        â†“
PromptTemplate (Dynamic Formatting)
        â†“
Hugging Face LLM (Zephyr-7B)
        â†“
Structured Summary Output
</pre>

<hr>

<h2>ğŸ› ï¸ Tech Stack</h2>

<ul>
  <li>ğŸ Python</li>
  <li>ğŸ”— LangChain</li>
  <li>ğŸ¤– Hugging Face Inference API</li>
  <li>ğŸŒ Streamlit</li>
  <li>ğŸ§  Prompt Engineering</li>
</ul>

<hr>

<h2>âš™ï¸ Installation</h2>

<h4>1ï¸âƒ£ Clone the Repository</h4>

<pre>
git clone https://github.com/your-username/research-paper-summarizer.git
cd research-paper-summarizer
</pre>

<h4>2ï¸âƒ£ Create Virtual Environment</h4>

<pre>
python -m venv venv
venv\Scripts\activate
</pre>

<h4>3ï¸âƒ£ Install Dependencies</h4>

<pre>
pip install -r requirements.txt
</pre>

<h4>4ï¸âƒ£ Add Hugging Face API Token</h4>

Create a <code>.env</code> file:

<pre>
HUGGINGFACEHUB_API_TOKEN=your_token_here
</pre>

<hr>

<h2>â–¶ï¸ Run the Application</h2>

<pre>
streamlit run app.py
</pre>

Open in browser:
<pre>
http://localhost:8501
</pre>

<hr>

<h2>ğŸ§  Learning Highlights</h2>

<ul>
  <li>âœ” Practical LLM integration</li>
  <li>âœ” Structured prompt engineering</li>
  <li>âœ” Chain-based AI workflows</li>
  <li>âœ” API-driven model inference</li>
  <li>âœ” Interactive AI application deployment</li>
</ul>

<hr>

<h2>ğŸ”® Future Enhancements</h2>

<ul>
  <li>ğŸ“„ PDF upload & summarization</li>
  <li>ğŸ” arXiv API integration (RAG)</li>
  <li>ğŸ’¬ Conversational research assistant</li>
  <li>â˜ Deployment on Streamlit Cloud</li>
</ul>

<hr>

<p align="center">
<b>â­ If you find this project useful, consider giving it a star!</b>
</p>
